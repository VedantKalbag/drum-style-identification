{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.io import wavfile\n",
    "import scipy.fftpack as fft\n",
    "from scipy.signal import get_window\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import librosa\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score,balanced_accuracy_score,f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "names=['drummer', 'session', 'id', 'style', 'bpm', 'beat_type',\n",
    "       'time_signature', 'midi_filename', 'audio_filename', 'duration',\n",
    "       'split', 'audio', 'mfcc_mean', 'mfcc_std', 'delta_mfcc_mean',\n",
    "       'delta_mfcc_std', 'centroid_mean', 'centroid_std', 'rms_mean',\n",
    "       'rms_std', 'zcr_mean', 'zcr_std', 'crest_mean', 'crest_std',\n",
    "       'flux_mean', 'flux_std', 'onsets_mean', 'onsets_std', 'mfcc1_mean',\n",
    "       'mfcc2_mean', 'mfcc3_mean', 'mfcc4_mean', 'mfcc5_mean', 'mfcc6_mean',\n",
    "       'mfcc7_mean', 'mfcc8_mean', 'mfcc9_mean', 'mfcc10_mean', 'mfcc11_mean',\n",
    "       'mfcc12_mean', 'mfcc13_mean', 'mfcc1_std', 'mfcc2_std', 'mfcc3_std',\n",
    "       'mfcc4_std', 'mfcc5_std', 'mfcc6_std', 'mfcc7_std', 'mfcc8_std',\n",
    "       'mfcc9_std', 'mfcc10_std', 'mfcc11_std', 'mfcc12_std', 'mfcc13_std',\n",
    "       'delta_mfcc1_mean', 'delta_mfcc2_mean', 'delta_mfcc3_mean',\n",
    "       'delta_mfcc4_mean', 'delta_mfcc5_mean', 'delta_mfcc6_mean',\n",
    "       'delta_mfcc7_mean', 'delta_mfcc8_mean', 'delta_mfcc9_mean',\n",
    "       'delta_mfcc10_mean', 'delta_mfcc11_mean', 'delta_mfcc12_mean',\n",
    "       'delta_mfcc13_mean', 'delta_mfcc1_std', 'delta_mfcc2_std',\n",
    "       'delta_mfcc3_std', 'delta_mfcc4_std', 'delta_mfcc5_std',\n",
    "       'delta_mfcc6_std', 'delta_mfcc7_std', 'delta_mfcc8_std',\n",
    "       'delta_mfcc9_std', 'delta_mfcc10_std', 'delta_mfcc11_std',\n",
    "       'delta_mfcc12_std', 'delta_mfcc13_std', 'onsets_low_mean',\n",
    "       'onsets_low_std','onsets_mid_mean', 'onsets_mid_std',\n",
    "       'onsets_high_mean', 'onsets_high_std']\n",
    "df=pd.DataFrame(np.load('./resources/working_data/data.npy',allow_pickle=True),columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['mfcc1_mean', 'mfcc2_mean', 'mfcc3_mean',\n",
    "       'mfcc4_mean', 'mfcc5_mean', 'mfcc6_mean', 'mfcc7_mean', 'mfcc8_mean',\n",
    "       'mfcc9_mean', 'mfcc10_mean', 'mfcc11_mean', 'mfcc12_mean',\n",
    "       'mfcc13_mean', 'mfcc1_std', 'mfcc2_std', 'mfcc3_std', 'mfcc4_std',\n",
    "       'mfcc5_std', 'mfcc6_std', 'mfcc7_std', 'mfcc8_std', 'mfcc9_std',\n",
    "       'mfcc10_std', 'mfcc11_std', 'mfcc12_std', 'mfcc13_std',\n",
    "       'delta_mfcc1_mean', 'delta_mfcc2_mean', 'delta_mfcc3_mean',\n",
    "       'delta_mfcc4_mean', 'delta_mfcc5_mean', 'delta_mfcc6_mean',\n",
    "       'delta_mfcc7_mean', 'delta_mfcc8_mean', 'delta_mfcc9_mean',\n",
    "       'delta_mfcc10_mean', 'delta_mfcc11_mean', 'delta_mfcc12_mean',\n",
    "       'delta_mfcc13_mean', 'delta_mfcc1_std', 'delta_mfcc2_std',\n",
    "       'delta_mfcc3_std', 'delta_mfcc4_std', 'delta_mfcc5_std',\n",
    "       'delta_mfcc6_std', 'delta_mfcc7_std', 'delta_mfcc8_std',\n",
    "       'delta_mfcc9_std', 'delta_mfcc10_std', 'delta_mfcc11_std',\n",
    "       'delta_mfcc12_std', 'delta_mfcc13_std',\n",
    "       'centroid_mean','centroid_std','rms_mean','rms_std','zcr_mean','zcr_std','crest_mean','crest_std','flux_mean',\n",
    "       'flux_std','onsets_mean', 'onsets_std','onsets_mid_mean', 'onsets_mid_std',\n",
    "       'onsets_high_mean', 'onsets_high_std',\n",
    "       'bpm']]\n",
    "y=df[['style']]\n",
    "\n",
    "# for col in X.columns:\n",
    "#     #df[col] = df[col]/max(np.abs(df[col]))\n",
    "#     mean = np.mean(X[col])\n",
    "#     std = np.std(X[col])\n",
    "#     X[col] = (X[col] - mean)/std # z-score normalization\n",
    "\n",
    "X_train, X_test1, y_train, y_test1 = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_test1 = X_test1.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test1 = y_test1.to_numpy()\n",
    "\n",
    "X_test,X_valid,y_test,y_valid = train_test_split(X_test1,y_test1,test_size=0.5)\n",
    "\n",
    "# X_train = X_train.reshape(-1, 69)\n",
    "# X_test = X_test.reshape(-1, 69)\n",
    "# X_valid = X_valid.reshape(-1, 69)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_valid = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train=le.fit_transform(y_train)\n",
    "y_test=le.transform(y_test)\n",
    "y_valid=le.transform(y_valid)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "y_valid_hot = to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Users/vedant/Desktop/Programming/ACA-project/trained_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148, 69)\n",
      "(49, 69)\n",
      "(50, 69)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "def train_models(X_train,y_train_hot,X_test,y_test_hot,epochs,batch_size,lr,layer1_nodes,optimiser,loss,verbose,save=False,seed_value=42):\n",
    "    tf.random.set_seed(seed_value)\n",
    "    model = Sequential()\n",
    "    input_shape = (69,1)#(128, 87, 1)\n",
    "    # model.add(Dense(128, activation='relu'))\n",
    "    # model.add(Dense(6, activation='softmax'))\n",
    "    model.add(Dense(layer1_nodes,input_dim=69, activation='relu'))\n",
    "    model.add(Dense(layer1_nodes,input_dim=32, activation='relu'))\n",
    "    model.add(Dense(layer1_nodes,input_dim=8, activation='relu'))\n",
    "    # model.add(Dense(32, activation='relu'))\n",
    "    # model.add(Dense(16, activation='relu'))\n",
    "    # model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    if optimiser=='adadelta':\n",
    "        optim=keras.optimizers.Adadelta(learning_rate=lr)\n",
    "    if optimiser == 'adam':\n",
    "        optim=keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    if loss == 'crossentropy':\n",
    "        loss_fn = keras.losses.categorical_crossentropy\n",
    "\n",
    "    model.compile(loss=loss_fn,\n",
    "                optimizer=optim,\n",
    "                metrics=['accuracy'])\n",
    "    model.build(input_shape)\n",
    "    model.summary()\n",
    "    # fit the model\n",
    "    history=model.fit(X_train, y_train_hot,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=verbose,\n",
    "            validation_data=(X_test, y_test_hot))\n",
    "    training_loss=history.history['loss']\n",
    "    validation_loss=history.history['val_loss']\n",
    "    training_acc=history.history['accuracy']\n",
    "    validation_acc=history.history['val_accuracy']\n",
    "    df=pd.DataFrame()\n",
    "    df['training_loss'] = training_loss\n",
    "    df['validation_loss'] = validation_loss\n",
    "    df['training_acc'] = training_acc\n",
    "    df['validation_acc'] = validation_acc\n",
    "    lr_str=str(lr).replace('.','_')\n",
    "    model_name=f'fcnn_layer1-{layer1_nodes}_batch-{batch_size}_epochs-{epochs}_lr-{lr_str}'\n",
    "    if save:\n",
    "        model.save(f'{path}/{model_name}')\n",
    "        df.to_csv(f'{path}/{model_name}.csv')\n",
    "\n",
    "    trace1 = go.Scatter(\n",
    "    x=df.index,\n",
    "        y=df['training_loss'],\n",
    "        name='Training Loss'\n",
    "    )\n",
    "    trace2 = go.Scatter(\n",
    "        x=df.index,\n",
    "        y=df['validation_loss'],\n",
    "        name='Validation Loss'\n",
    "    )\n",
    "    trace3 = go.Scatter(\n",
    "        x=df.index,\n",
    "        y=df['training_acc'],\n",
    "        name='Training Accuracy',\n",
    "        yaxis='y2'\n",
    "    )\n",
    "    trace4 = go.Scatter(\n",
    "        x=df.index,\n",
    "        y=df['validation_acc'],\n",
    "        name='Validation Accuracy',\n",
    "        yaxis='y2'\n",
    "    )\n",
    "\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    fig.add_trace(trace1)\n",
    "    fig.add_trace(trace2)\n",
    "    fig.add_trace(trace3,secondary_y=True)\n",
    "    fig.add_trace(trace4,secondary_y=True)\n",
    "    fig.show()\n",
    "    return model,df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 32)                2240      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 4,484\n",
      "Trainable params: 4,484\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 1.3062 - accuracy: 0.4527 - val_loss: 1.2412 - val_accuracy: 0.4694\n",
      "Epoch 2/150\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.2733 - accuracy: 0.5068 - val_loss: 1.2211 - val_accuracy: 0.5510\n",
      "Epoch 3/150\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.2448 - accuracy: 0.5270 - val_loss: 1.2008 - val_accuracy: 0.5306\n",
      "Epoch 4/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.2175 - accuracy: 0.5608 - val_loss: 1.1801 - val_accuracy: 0.5714\n",
      "Epoch 5/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.1916 - accuracy: 0.6081 - val_loss: 1.1596 - val_accuracy: 0.6327\n",
      "Epoch 6/150\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.1667 - accuracy: 0.6216 - val_loss: 1.1395 - val_accuracy: 0.6531\n",
      "Epoch 7/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1429 - accuracy: 0.6554 - val_loss: 1.1201 - val_accuracy: 0.6531\n",
      "Epoch 8/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1195 - accuracy: 0.6622 - val_loss: 1.1020 - val_accuracy: 0.6531\n",
      "Epoch 9/150\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0978 - accuracy: 0.6622 - val_loss: 1.0850 - val_accuracy: 0.6735\n",
      "Epoch 10/150\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0769 - accuracy: 0.6622 - val_loss: 1.0683 - val_accuracy: 0.6735\n",
      "Epoch 11/150\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0572 - accuracy: 0.6689 - val_loss: 1.0515 - val_accuracy: 0.6735\n",
      "Epoch 12/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0389 - accuracy: 0.6689 - val_loss: 1.0352 - val_accuracy: 0.6735\n",
      "Epoch 13/150\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0207 - accuracy: 0.6689 - val_loss: 1.0194 - val_accuracy: 0.6735\n",
      "Epoch 14/150\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0041 - accuracy: 0.6689 - val_loss: 1.0043 - val_accuracy: 0.6735\n",
      "Epoch 15/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.9877 - accuracy: 0.6689 - val_loss: 0.9900 - val_accuracy: 0.6735\n",
      "Epoch 16/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.9724 - accuracy: 0.6689 - val_loss: 0.9764 - val_accuracy: 0.6735\n",
      "Epoch 17/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.9580 - accuracy: 0.6689 - val_loss: 0.9637 - val_accuracy: 0.6735\n",
      "Epoch 18/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.9450 - accuracy: 0.6689 - val_loss: 0.9518 - val_accuracy: 0.6735\n",
      "Epoch 19/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.9319 - accuracy: 0.6689 - val_loss: 0.9412 - val_accuracy: 0.6735\n",
      "Epoch 20/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.9203 - accuracy: 0.6689 - val_loss: 0.9318 - val_accuracy: 0.6735\n",
      "Epoch 21/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.9086 - accuracy: 0.6689 - val_loss: 0.9234 - val_accuracy: 0.6735\n",
      "Epoch 22/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8979 - accuracy: 0.6689 - val_loss: 0.9158 - val_accuracy: 0.6735\n",
      "Epoch 23/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8871 - accuracy: 0.6689 - val_loss: 0.9088 - val_accuracy: 0.6735\n",
      "Epoch 24/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8773 - accuracy: 0.6689 - val_loss: 0.9016 - val_accuracy: 0.6735\n",
      "Epoch 25/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8671 - accuracy: 0.6689 - val_loss: 0.8947 - val_accuracy: 0.6735\n",
      "Epoch 26/150\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.8578 - accuracy: 0.6689 - val_loss: 0.8888 - val_accuracy: 0.6735\n",
      "Epoch 27/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.8483 - accuracy: 0.6689 - val_loss: 0.8837 - val_accuracy: 0.6735\n",
      "Epoch 28/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8393 - accuracy: 0.6689 - val_loss: 0.8786 - val_accuracy: 0.6735\n",
      "Epoch 29/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8307 - accuracy: 0.6689 - val_loss: 0.8734 - val_accuracy: 0.6735\n",
      "Epoch 30/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8218 - accuracy: 0.6689 - val_loss: 0.8682 - val_accuracy: 0.6735\n",
      "Epoch 31/150\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.8131 - accuracy: 0.6757 - val_loss: 0.8630 - val_accuracy: 0.6735\n",
      "Epoch 32/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.8043 - accuracy: 0.6757 - val_loss: 0.8580 - val_accuracy: 0.6735\n",
      "Epoch 33/150\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.7955 - accuracy: 0.6757 - val_loss: 0.8535 - val_accuracy: 0.6735\n",
      "Epoch 34/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7866 - accuracy: 0.6757 - val_loss: 0.8494 - val_accuracy: 0.6735\n",
      "Epoch 35/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7784 - accuracy: 0.6757 - val_loss: 0.8450 - val_accuracy: 0.6735\n",
      "Epoch 36/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.7695 - accuracy: 0.6757 - val_loss: 0.8404 - val_accuracy: 0.6735\n",
      "Epoch 37/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7610 - accuracy: 0.6757 - val_loss: 0.8360 - val_accuracy: 0.6735\n",
      "Epoch 38/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7525 - accuracy: 0.6757 - val_loss: 0.8311 - val_accuracy: 0.6735\n",
      "Epoch 39/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7439 - accuracy: 0.6757 - val_loss: 0.8258 - val_accuracy: 0.6735\n",
      "Epoch 40/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7354 - accuracy: 0.6757 - val_loss: 0.8204 - val_accuracy: 0.6735\n",
      "Epoch 41/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7266 - accuracy: 0.6757 - val_loss: 0.8153 - val_accuracy: 0.6735\n",
      "Epoch 42/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7174 - accuracy: 0.6757 - val_loss: 0.8104 - val_accuracy: 0.6735\n",
      "Epoch 43/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7088 - accuracy: 0.6757 - val_loss: 0.8058 - val_accuracy: 0.6735\n",
      "Epoch 44/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6998 - accuracy: 0.6757 - val_loss: 0.8013 - val_accuracy: 0.6735\n",
      "Epoch 45/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6906 - accuracy: 0.6757 - val_loss: 0.7975 - val_accuracy: 0.6735\n",
      "Epoch 46/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6819 - accuracy: 0.6757 - val_loss: 0.7938 - val_accuracy: 0.6735\n",
      "Epoch 47/150\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6732 - accuracy: 0.6757 - val_loss: 0.7904 - val_accuracy: 0.6735\n",
      "Epoch 48/150\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6640 - accuracy: 0.6892 - val_loss: 0.7866 - val_accuracy: 0.6531\n",
      "Epoch 49/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6549 - accuracy: 0.6892 - val_loss: 0.7824 - val_accuracy: 0.6531\n",
      "Epoch 50/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6456 - accuracy: 0.6959 - val_loss: 0.7786 - val_accuracy: 0.6531\n",
      "Epoch 51/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6358 - accuracy: 0.6892 - val_loss: 0.7750 - val_accuracy: 0.6531\n",
      "Epoch 52/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6264 - accuracy: 0.6892 - val_loss: 0.7710 - val_accuracy: 0.6735\n",
      "Epoch 53/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6164 - accuracy: 0.6959 - val_loss: 0.7667 - val_accuracy: 0.6939\n",
      "Epoch 54/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6065 - accuracy: 0.7027 - val_loss: 0.7622 - val_accuracy: 0.6939\n",
      "Epoch 55/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5974 - accuracy: 0.7162 - val_loss: 0.7575 - val_accuracy: 0.6939\n",
      "Epoch 56/150\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5877 - accuracy: 0.7297 - val_loss: 0.7528 - val_accuracy: 0.6735\n",
      "Epoch 57/150\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5786 - accuracy: 0.7432 - val_loss: 0.7480 - val_accuracy: 0.6735\n",
      "Epoch 58/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5697 - accuracy: 0.7432 - val_loss: 0.7434 - val_accuracy: 0.6735\n",
      "Epoch 59/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5608 - accuracy: 0.7500 - val_loss: 0.7388 - val_accuracy: 0.6735\n",
      "Epoch 60/150\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5519 - accuracy: 0.7568 - val_loss: 0.7344 - val_accuracy: 0.6735\n",
      "Epoch 61/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5429 - accuracy: 0.7703 - val_loss: 0.7304 - val_accuracy: 0.6735\n",
      "Epoch 62/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5347 - accuracy: 0.7770 - val_loss: 0.7264 - val_accuracy: 0.6735\n",
      "Epoch 63/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5270 - accuracy: 0.7838 - val_loss: 0.7227 - val_accuracy: 0.6735\n",
      "Epoch 64/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5185 - accuracy: 0.8108 - val_loss: 0.7199 - val_accuracy: 0.6735\n",
      "Epoch 65/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5106 - accuracy: 0.8311 - val_loss: 0.7182 - val_accuracy: 0.6939\n",
      "Epoch 66/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5033 - accuracy: 0.8446 - val_loss: 0.7174 - val_accuracy: 0.7143\n",
      "Epoch 67/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4955 - accuracy: 0.8378 - val_loss: 0.7168 - val_accuracy: 0.7143\n",
      "Epoch 68/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4875 - accuracy: 0.8446 - val_loss: 0.7164 - val_accuracy: 0.7143\n",
      "Epoch 69/150\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4795 - accuracy: 0.8446 - val_loss: 0.7160 - val_accuracy: 0.7143\n",
      "Epoch 70/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4716 - accuracy: 0.8446 - val_loss: 0.7148 - val_accuracy: 0.7347\n",
      "Epoch 71/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4634 - accuracy: 0.8581 - val_loss: 0.7133 - val_accuracy: 0.7347\n",
      "Epoch 72/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4553 - accuracy: 0.8581 - val_loss: 0.7123 - val_accuracy: 0.7347\n",
      "Epoch 73/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4473 - accuracy: 0.8649 - val_loss: 0.7113 - val_accuracy: 0.7347\n",
      "Epoch 74/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4395 - accuracy: 0.8649 - val_loss: 0.7095 - val_accuracy: 0.7347\n",
      "Epoch 75/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4314 - accuracy: 0.8649 - val_loss: 0.7081 - val_accuracy: 0.7347\n",
      "Epoch 76/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4233 - accuracy: 0.8649 - val_loss: 0.7073 - val_accuracy: 0.7347\n",
      "Epoch 77/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4155 - accuracy: 0.8716 - val_loss: 0.7063 - val_accuracy: 0.7347\n",
      "Epoch 78/150\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4077 - accuracy: 0.8784 - val_loss: 0.7052 - val_accuracy: 0.7551\n",
      "Epoch 79/150\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4000 - accuracy: 0.8919 - val_loss: 0.7040 - val_accuracy: 0.7551\n",
      "Epoch 80/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3926 - accuracy: 0.8986 - val_loss: 0.7025 - val_accuracy: 0.7551\n",
      "Epoch 81/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3857 - accuracy: 0.8919 - val_loss: 0.7009 - val_accuracy: 0.7551\n",
      "Epoch 82/150\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3786 - accuracy: 0.8919 - val_loss: 0.6994 - val_accuracy: 0.7551\n",
      "Epoch 83/150\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3719 - accuracy: 0.8919 - val_loss: 0.6981 - val_accuracy: 0.7551\n",
      "Epoch 84/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3656 - accuracy: 0.8919 - val_loss: 0.6971 - val_accuracy: 0.7551\n",
      "Epoch 85/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3593 - accuracy: 0.8986 - val_loss: 0.6968 - val_accuracy: 0.7551\n",
      "Epoch 86/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3528 - accuracy: 0.8919 - val_loss: 0.6961 - val_accuracy: 0.7551\n",
      "Epoch 87/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3465 - accuracy: 0.8986 - val_loss: 0.6948 - val_accuracy: 0.7551\n",
      "Epoch 88/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3401 - accuracy: 0.8919 - val_loss: 0.6934 - val_accuracy: 0.7551\n",
      "Epoch 89/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3338 - accuracy: 0.8986 - val_loss: 0.6915 - val_accuracy: 0.7551\n",
      "Epoch 90/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3278 - accuracy: 0.8986 - val_loss: 0.6900 - val_accuracy: 0.7551\n",
      "Epoch 91/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3219 - accuracy: 0.8986 - val_loss: 0.6897 - val_accuracy: 0.7551\n",
      "Epoch 92/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3162 - accuracy: 0.8986 - val_loss: 0.6903 - val_accuracy: 0.7755\n",
      "Epoch 93/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3115 - accuracy: 0.9054 - val_loss: 0.6905 - val_accuracy: 0.7755\n",
      "Epoch 94/150\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3068 - accuracy: 0.9189 - val_loss: 0.6901 - val_accuracy: 0.7755\n",
      "Epoch 95/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3013 - accuracy: 0.9257 - val_loss: 0.6897 - val_accuracy: 0.7755\n",
      "Epoch 96/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2959 - accuracy: 0.9324 - val_loss: 0.6897 - val_accuracy: 0.7755\n",
      "Epoch 97/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2904 - accuracy: 0.9392 - val_loss: 0.6898 - val_accuracy: 0.7755\n",
      "Epoch 98/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2850 - accuracy: 0.9392 - val_loss: 0.6898 - val_accuracy: 0.7755\n",
      "Epoch 99/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2800 - accuracy: 0.9324 - val_loss: 0.6904 - val_accuracy: 0.7755\n",
      "Epoch 100/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2750 - accuracy: 0.9324 - val_loss: 0.6905 - val_accuracy: 0.7755\n",
      "Epoch 101/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2701 - accuracy: 0.9324 - val_loss: 0.6903 - val_accuracy: 0.7755\n",
      "Epoch 102/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2654 - accuracy: 0.9324 - val_loss: 0.6900 - val_accuracy: 0.7755\n",
      "Epoch 103/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2610 - accuracy: 0.9324 - val_loss: 0.6900 - val_accuracy: 0.7959\n",
      "Epoch 104/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2570 - accuracy: 0.9324 - val_loss: 0.6901 - val_accuracy: 0.7959\n",
      "Epoch 105/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2526 - accuracy: 0.9392 - val_loss: 0.6897 - val_accuracy: 0.7959\n",
      "Epoch 106/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2482 - accuracy: 0.9392 - val_loss: 0.6897 - val_accuracy: 0.7959\n",
      "Epoch 107/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2437 - accuracy: 0.9392 - val_loss: 0.6906 - val_accuracy: 0.7959\n",
      "Epoch 108/150\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2395 - accuracy: 0.9392 - val_loss: 0.6926 - val_accuracy: 0.7959\n",
      "Epoch 109/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2354 - accuracy: 0.9392 - val_loss: 0.6962 - val_accuracy: 0.7959\n",
      "Epoch 110/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2315 - accuracy: 0.9459 - val_loss: 0.6997 - val_accuracy: 0.7959\n",
      "Epoch 111/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2282 - accuracy: 0.9459 - val_loss: 0.7010 - val_accuracy: 0.7959\n",
      "Epoch 112/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2237 - accuracy: 0.9527 - val_loss: 0.6996 - val_accuracy: 0.7959\n",
      "Epoch 113/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2193 - accuracy: 0.9527 - val_loss: 0.6980 - val_accuracy: 0.7959\n",
      "Epoch 114/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2153 - accuracy: 0.9527 - val_loss: 0.6975 - val_accuracy: 0.7755\n",
      "Epoch 115/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2123 - accuracy: 0.9595 - val_loss: 0.6978 - val_accuracy: 0.7755\n",
      "Epoch 116/150\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2093 - accuracy: 0.9527 - val_loss: 0.6988 - val_accuracy: 0.7755\n",
      "Epoch 117/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2061 - accuracy: 0.9527 - val_loss: 0.6999 - val_accuracy: 0.7755\n",
      "Epoch 118/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2027 - accuracy: 0.9527 - val_loss: 0.7010 - val_accuracy: 0.7755\n",
      "Epoch 119/150\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1990 - accuracy: 0.9527 - val_loss: 0.7016 - val_accuracy: 0.7959\n",
      "Epoch 120/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1951 - accuracy: 0.9527 - val_loss: 0.7019 - val_accuracy: 0.7959\n",
      "Epoch 121/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1911 - accuracy: 0.9527 - val_loss: 0.7039 - val_accuracy: 0.7959\n",
      "Epoch 122/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1879 - accuracy: 0.9595 - val_loss: 0.7072 - val_accuracy: 0.7959\n",
      "Epoch 123/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1842 - accuracy: 0.9595 - val_loss: 0.7100 - val_accuracy: 0.7755\n",
      "Epoch 124/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1811 - accuracy: 0.9662 - val_loss: 0.7125 - val_accuracy: 0.7755\n",
      "Epoch 125/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1784 - accuracy: 0.9662 - val_loss: 0.7129 - val_accuracy: 0.7959\n",
      "Epoch 126/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1755 - accuracy: 0.9662 - val_loss: 0.7118 - val_accuracy: 0.7959\n",
      "Epoch 127/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1725 - accuracy: 0.9662 - val_loss: 0.7109 - val_accuracy: 0.7959\n",
      "Epoch 128/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1697 - accuracy: 0.9662 - val_loss: 0.7093 - val_accuracy: 0.7959\n",
      "Epoch 129/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1669 - accuracy: 0.9662 - val_loss: 0.7083 - val_accuracy: 0.7959\n",
      "Epoch 130/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1640 - accuracy: 0.9662 - val_loss: 0.7081 - val_accuracy: 0.7959\n",
      "Epoch 131/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1610 - accuracy: 0.9662 - val_loss: 0.7084 - val_accuracy: 0.8163\n",
      "Epoch 132/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1582 - accuracy: 0.9730 - val_loss: 0.7087 - val_accuracy: 0.8163\n",
      "Epoch 133/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1556 - accuracy: 0.9797 - val_loss: 0.7090 - val_accuracy: 0.8163\n",
      "Epoch 134/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1530 - accuracy: 0.9797 - val_loss: 0.7099 - val_accuracy: 0.8163\n",
      "Epoch 135/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1505 - accuracy: 0.9797 - val_loss: 0.7115 - val_accuracy: 0.8163\n",
      "Epoch 136/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1484 - accuracy: 0.9797 - val_loss: 0.7130 - val_accuracy: 0.8163\n",
      "Epoch 137/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1461 - accuracy: 0.9797 - val_loss: 0.7135 - val_accuracy: 0.8163\n",
      "Epoch 138/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1437 - accuracy: 0.9797 - val_loss: 0.7132 - val_accuracy: 0.8163\n",
      "Epoch 139/150\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1413 - accuracy: 0.9797 - val_loss: 0.7127 - val_accuracy: 0.8163\n",
      "Epoch 140/150\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1387 - accuracy: 0.9797 - val_loss: 0.7129 - val_accuracy: 0.8163\n",
      "Epoch 141/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1360 - accuracy: 0.9865 - val_loss: 0.7120 - val_accuracy: 0.8163\n",
      "Epoch 142/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1338 - accuracy: 0.9932 - val_loss: 0.7102 - val_accuracy: 0.8367\n",
      "Epoch 143/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1312 - accuracy: 0.9932 - val_loss: 0.7084 - val_accuracy: 0.8367\n",
      "Epoch 144/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1290 - accuracy: 0.9932 - val_loss: 0.7065 - val_accuracy: 0.8367\n",
      "Epoch 145/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1271 - accuracy: 0.9865 - val_loss: 0.7053 - val_accuracy: 0.8367\n",
      "Epoch 146/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1247 - accuracy: 0.9932 - val_loss: 0.7036 - val_accuracy: 0.8367\n",
      "Epoch 147/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1223 - accuracy: 0.9932 - val_loss: 0.7022 - val_accuracy: 0.8367\n",
      "Epoch 148/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1196 - accuracy: 0.9932 - val_loss: 0.7013 - val_accuracy: 0.8367\n",
      "Epoch 149/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1178 - accuracy: 0.9932 - val_loss: 0.7007 - val_accuracy: 0.8367\n",
      "Epoch 150/150\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1154 - accuracy: 0.9932 - val_loss: 0.7006 - val_accuracy: 0.8367\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Training Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149
         ],
         "y": [
          1.3062260150909424,
          1.273341178894043,
          1.244766354560852,
          1.2175318002700806,
          1.1916371583938599,
          1.1667203903198242,
          1.1429493427276611,
          1.1194614171981812,
          1.0977840423583984,
          1.0769379138946533,
          1.0572117567062378,
          1.0388851165771484,
          1.0206866264343262,
          1.0041265487670898,
          0.9876586198806763,
          0.9723824262619019,
          0.957951545715332,
          0.9449676275253296,
          0.931867778301239,
          0.9202540516853333,
          0.9086266756057739,
          0.8978830575942993,
          0.8870882391929626,
          0.8772506713867188,
          0.8671254515647888,
          0.8578096032142639,
          0.848330557346344,
          0.8392948508262634,
          0.8307427763938904,
          0.8218268156051636,
          0.8130607604980469,
          0.8042776584625244,
          0.7955285906791687,
          0.7866318821907043,
          0.7784189581871033,
          0.7694574594497681,
          0.7610284686088562,
          0.7524677515029907,
          0.7438815832138062,
          0.7354426980018616,
          0.7266092300415039,
          0.7174341082572937,
          0.7088106274604797,
          0.6998279690742493,
          0.6905891299247742,
          0.6819148659706116,
          0.6732020378112793,
          0.6640470623970032,
          0.6549404263496399,
          0.6456187963485718,
          0.6358428001403809,
          0.6264139413833618,
          0.6163859367370605,
          0.6065454483032227,
          0.5974096059799194,
          0.5877418518066406,
          0.5786364674568176,
          0.5696807503700256,
          0.560847282409668,
          0.5518696904182434,
          0.5428879261016846,
          0.5346842408180237,
          0.526951014995575,
          0.5185095071792603,
          0.5106494426727295,
          0.5033055543899536,
          0.49546000361442566,
          0.48747047781944275,
          0.4795472025871277,
          0.4716440737247467,
          0.4633522033691406,
          0.4552619457244873,
          0.44727107882499695,
          0.4394514262676239,
          0.43143904209136963,
          0.4233418405056,
          0.4155348837375641,
          0.4076524078845978,
          0.39999550580978394,
          0.3925895094871521,
          0.3856579661369324,
          0.37863045930862427,
          0.37191861867904663,
          0.36564692854881287,
          0.3592730462551117,
          0.3528333902359009,
          0.34652337431907654,
          0.34005725383758545,
          0.3338398039340973,
          0.327813982963562,
          0.3219013810157776,
          0.3162063658237457,
          0.31154683232307434,
          0.30675554275512695,
          0.3012886941432953,
          0.2958916425704956,
          0.2904015779495239,
          0.2850203514099121,
          0.2799764573574066,
          0.27498766779899597,
          0.27007150650024414,
          0.26539140939712524,
          0.26100602746009827,
          0.2570357918739319,
          0.2525842487812042,
          0.2481818050146103,
          0.2436564713716507,
          0.23951007425785065,
          0.2354355901479721,
          0.23152422904968262,
          0.22822782397270203,
          0.22370409965515137,
          0.21934939920902252,
          0.2152523547410965,
          0.2123044729232788,
          0.20933756232261658,
          0.2060871720314026,
          0.20267724990844727,
          0.19903847575187683,
          0.1951483190059662,
          0.19109803438186646,
          0.18785984814167023,
          0.18420307338237762,
          0.18111802637577057,
          0.17843256890773773,
          0.17549459636211395,
          0.17251896858215332,
          0.16973507404327393,
          0.16687972843647003,
          0.16403523087501526,
          0.16104444861412048,
          0.15822872519493103,
          0.15560756623744965,
          0.15300163626670837,
          0.15050320327281952,
          0.14842568337917328,
          0.14612041413784027,
          0.14368435740470886,
          0.14125287532806396,
          0.1386776715517044,
          0.135960653424263,
          0.13382162153720856,
          0.13122276961803436,
          0.12896305322647095,
          0.127139613032341,
          0.12474735081195831,
          0.122340627014637,
          0.11963554471731186,
          0.11779415607452393,
          0.11538299173116684
         ]
        },
        {
         "name": "Validation Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149
         ],
         "y": [
          1.2411831617355347,
          1.2211179733276367,
          1.2007722854614258,
          1.1801011562347412,
          1.159566879272461,
          1.1394705772399902,
          1.1200816631317139,
          1.1020057201385498,
          1.0849997997283936,
          1.0683451890945435,
          1.0514768362045288,
          1.0351996421813965,
          1.0194263458251953,
          1.0042965412139893,
          0.9899694323539734,
          0.9763718247413635,
          0.9636683464050293,
          0.9517713189125061,
          0.9412103891372681,
          0.9318357110023499,
          0.923382043838501,
          0.9158357977867126,
          0.9088233709335327,
          0.9015721082687378,
          0.89466392993927,
          0.8888013958930969,
          0.8837141990661621,
          0.8786002993583679,
          0.8733618855476379,
          0.8681976795196533,
          0.8629686236381531,
          0.8580090403556824,
          0.8534570932388306,
          0.849376380443573,
          0.8449916243553162,
          0.8403936624526978,
          0.8359781503677368,
          0.8311215043067932,
          0.8257508277893066,
          0.820366621017456,
          0.8152554631233215,
          0.8103924989700317,
          0.8057873249053955,
          0.80133455991745,
          0.7975410223007202,
          0.7937604784965515,
          0.7903655171394348,
          0.7866465449333191,
          0.7824440002441406,
          0.7785706520080566,
          0.7749764323234558,
          0.7710205912590027,
          0.7667352557182312,
          0.7621986865997314,
          0.7574748396873474,
          0.7527614235877991,
          0.7480184435844421,
          0.7434107065200806,
          0.7388335466384888,
          0.7344486713409424,
          0.7303622364997864,
          0.7264369130134583,
          0.7227492332458496,
          0.7199364304542542,
          0.7181816101074219,
          0.7173616290092468,
          0.7167706489562988,
          0.7163512706756592,
          0.7159674763679504,
          0.714835524559021,
          0.7133106589317322,
          0.7122936844825745,
          0.7112935185432434,
          0.7095077037811279,
          0.7081454396247864,
          0.7072969675064087,
          0.7062653303146362,
          0.705219566822052,
          0.7039818167686462,
          0.70245760679245,
          0.7009096741676331,
          0.699432373046875,
          0.6981015801429749,
          0.697145402431488,
          0.6968144178390503,
          0.6960862874984741,
          0.694823145866394,
          0.693395733833313,
          0.6915159225463867,
          0.690025806427002,
          0.6896998882293701,
          0.6902873516082764,
          0.6905290484428406,
          0.690102219581604,
          0.6896592974662781,
          0.6896564960479736,
          0.6897748112678528,
          0.6897984147071838,
          0.6903598308563232,
          0.6905093789100647,
          0.6902539134025574,
          0.6899826526641846,
          0.6899590492248535,
          0.690061628818512,
          0.6896830201148987,
          0.6896830201148987,
          0.6905705332756042,
          0.6926167607307434,
          0.6962293386459351,
          0.6996775269508362,
          0.7010192275047302,
          0.6995551586151123,
          0.6980056762695312,
          0.6975414752960205,
          0.6977684497833252,
          0.6988126039505005,
          0.6999201774597168,
          0.7009503245353699,
          0.7016444802284241,
          0.7018775343894958,
          0.7038559317588806,
          0.7071584463119507,
          0.71001797914505,
          0.7124506831169128,
          0.7129302024841309,
          0.7118021845817566,
          0.7109026908874512,
          0.7093490958213806,
          0.7083022594451904,
          0.7081043720245361,
          0.7084048390388489,
          0.7087011337280273,
          0.7090060114860535,
          0.7099063396453857,
          0.7114931344985962,
          0.7129907608032227,
          0.7135406136512756,
          0.7131680846214294,
          0.7127388119697571,
          0.7129124999046326,
          0.7120227217674255,
          0.7102276682853699,
          0.7084469795227051,
          0.7065435647964478,
          0.7053022384643555,
          0.7035512328147888,
          0.7021704912185669,
          0.7012843489646912,
          0.700739324092865,
          0.7005710005760193
         ]
        },
        {
         "name": "Training Accuracy",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149
         ],
         "xaxis": "x",
         "y": [
          0.45270270109176636,
          0.5067567825317383,
          0.5270270109176636,
          0.5608108043670654,
          0.6081081032752991,
          0.6216216087341309,
          0.6554054021835327,
          0.662162184715271,
          0.662162184715271,
          0.662162184715271,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6689189076423645,
          0.6756756901741028,
          0.6756756901741028,
          0.6756756901741028,
          0.6756756901741028,
          0.6756756901741028,
          0.6756756901741028,
          0.6756756901741028,
          0.6756756901741028,
          0.6756756901741028,
          0.6756756901741028,
          0.6756756901741028,
          0.6756756901741028,
          0.6756756901741028,
          0.6756756901741028,
          0.6756756901741028,
          0.6756756901741028,
          0.6756756901741028,
          0.6891891956329346,
          0.6891891956329346,
          0.6959459185600281,
          0.6891891956329346,
          0.6891891956329346,
          0.6959459185600281,
          0.7027027010917664,
          0.7162162065505981,
          0.7297297120094299,
          0.7432432174682617,
          0.7432432174682617,
          0.75,
          0.7567567825317383,
          0.7702702879905701,
          0.7770270109176636,
          0.7837837934494019,
          0.8108108043670654,
          0.8310810923576355,
          0.8445945978164673,
          0.837837815284729,
          0.8445945978164673,
          0.8445945978164673,
          0.8445945978164673,
          0.8581081032752991,
          0.8581081032752991,
          0.8648648858070374,
          0.8648648858070374,
          0.8648648858070374,
          0.8648648858070374,
          0.8716216087341309,
          0.8783783912658691,
          0.8918918967247009,
          0.8986486196517944,
          0.8918918967247009,
          0.8918918967247009,
          0.8918918967247009,
          0.8918918967247009,
          0.8986486196517944,
          0.8918918967247009,
          0.8986486196517944,
          0.8918918967247009,
          0.8986486196517944,
          0.8986486196517944,
          0.8986486196517944,
          0.8986486196517944,
          0.9054054021835327,
          0.9189189076423645,
          0.9256756901741028,
          0.9324324131011963,
          0.9391891956329346,
          0.9391891956329346,
          0.9324324131011963,
          0.9324324131011963,
          0.9324324131011963,
          0.9324324131011963,
          0.9324324131011963,
          0.9324324131011963,
          0.9391891956329346,
          0.9391891956329346,
          0.9391891956329346,
          0.9391891956329346,
          0.9391891956329346,
          0.9459459185600281,
          0.9459459185600281,
          0.9527027010917664,
          0.9527027010917664,
          0.9527027010917664,
          0.9594594836235046,
          0.9527027010917664,
          0.9527027010917664,
          0.9527027010917664,
          0.9527027010917664,
          0.9527027010917664,
          0.9527027010917664,
          0.9594594836235046,
          0.9594594836235046,
          0.9662162065505981,
          0.9662162065505981,
          0.9662162065505981,
          0.9662162065505981,
          0.9662162065505981,
          0.9662162065505981,
          0.9662162065505981,
          0.9662162065505981,
          0.9729729890823364,
          0.9797297120094299,
          0.9797297120094299,
          0.9797297120094299,
          0.9797297120094299,
          0.9797297120094299,
          0.9797297120094299,
          0.9797297120094299,
          0.9797297120094299,
          0.9864864945411682,
          0.9932432174682617,
          0.9932432174682617,
          0.9932432174682617,
          0.9864864945411682,
          0.9932432174682617,
          0.9932432174682617,
          0.9932432174682617,
          0.9932432174682617,
          0.9932432174682617
         ],
         "yaxis": "y2"
        },
        {
         "name": "Validation Accuracy",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149
         ],
         "xaxis": "x",
         "y": [
          0.4693877696990967,
          0.5510203838348389,
          0.5306122303009033,
          0.5714285969734192,
          0.6326530575752258,
          0.6530612111091614,
          0.6530612111091614,
          0.6530612111091614,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6530612111091614,
          0.6530612111091614,
          0.6530612111091614,
          0.6530612111091614,
          0.6734693646430969,
          0.6938775777816772,
          0.6938775777816772,
          0.6938775777816772,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6734693646430969,
          0.6938775777816772,
          0.7142857313156128,
          0.7142857313156128,
          0.7142857313156128,
          0.7142857313156128,
          0.7346938848495483,
          0.7346938848495483,
          0.7346938848495483,
          0.7346938848495483,
          0.7346938848495483,
          0.7346938848495483,
          0.7346938848495483,
          0.7346938848495483,
          0.7551020383834839,
          0.7551020383834839,
          0.7551020383834839,
          0.7551020383834839,
          0.7551020383834839,
          0.7551020383834839,
          0.7551020383834839,
          0.7551020383834839,
          0.7551020383834839,
          0.7551020383834839,
          0.7551020383834839,
          0.7551020383834839,
          0.7551020383834839,
          0.7551020383834839,
          0.7755101919174194,
          0.7755101919174194,
          0.7755101919174194,
          0.7755101919174194,
          0.7755101919174194,
          0.7755101919174194,
          0.7755101919174194,
          0.7755101919174194,
          0.7755101919174194,
          0.7755101919174194,
          0.7755101919174194,
          0.795918345451355,
          0.795918345451355,
          0.795918345451355,
          0.795918345451355,
          0.795918345451355,
          0.795918345451355,
          0.795918345451355,
          0.795918345451355,
          0.795918345451355,
          0.795918345451355,
          0.795918345451355,
          0.7755101919174194,
          0.7755101919174194,
          0.7755101919174194,
          0.7755101919174194,
          0.7755101919174194,
          0.795918345451355,
          0.795918345451355,
          0.795918345451355,
          0.795918345451355,
          0.7755101919174194,
          0.7755101919174194,
          0.795918345451355,
          0.795918345451355,
          0.795918345451355,
          0.795918345451355,
          0.795918345451355,
          0.795918345451355,
          0.8163265585899353,
          0.8163265585899353,
          0.8163265585899353,
          0.8163265585899353,
          0.8163265585899353,
          0.8163265585899353,
          0.8163265585899353,
          0.8163265585899353,
          0.8163265585899353,
          0.8163265585899353,
          0.8163265585899353,
          0.8367347121238708,
          0.8367347121238708,
          0.8367347121238708,
          0.8367347121238708,
          0.8367347121238708,
          0.8367347121238708,
          0.8367347121238708,
          0.8367347121238708,
          0.8367347121238708
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.94
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x",
         "overlaying": "y",
         "side": "right"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model,df=train_models(X_train,y_train_hot,X_test,y_test_hot,150,128,0.0005,32,'adam','crossentropy',verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_valid)\n",
    "y_pred[np.where(y_pred==np.max(y_pred))] = 1\n",
    "y_pred=np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  0  0  3]\n",
      " [ 1  3  0  2]\n",
      " [ 0  0  2  3]\n",
      " [ 1  3  0 31]]\n",
      "Accuracy Score:  0.74\n",
      "Macro accuracy Score: 0.5089285714285714\n",
      "F1 score: 0.5487451737451737\n"
     ]
    }
   ],
   "source": [
    "score=balanced_accuracy_score(y_valid, y_pred)\n",
    "cm = confusion_matrix(y_valid, y_pred)\n",
    "f1=f1_score(y_valid,y_pred,average='macro')\n",
    "acc = accuracy_score(y_valid, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(\"Accuracy Score: \",acc)\n",
    "print(\"Macro accuracy Score:\",score)\n",
    "print(f\"F1 score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
